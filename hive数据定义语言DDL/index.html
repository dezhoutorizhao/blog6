<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>hive数据定义语言DDL | h3110w0r1d's Blog</title><meta name="author" content="h3110w0r1d"><meta name="copyright" content="h3110w0r1d"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="hive数 据定义语言DDL数据定义语言概述   数据定义语言 (Data Definition Language, DDL)，是SQL语言集中对数据库内部的对象结构进行创建，删除，修改等的操作语言，这些数据库对象包括database（schema）、table、view、index等。   DDL核心语法由CREATE、ALTER与DROP三个所组成。DDL是对表结构进行的操作。   在某些上下">
<meta property="og:type" content="article">
<meta property="og:title" content="hive数据定义语言DDL">
<meta property="og:url" content="https://www.codexploit.cn/hive%E6%95%B0%E6%8D%AE%E5%AE%9A%E4%B9%89%E8%AF%AD%E8%A8%80DDL/index.html">
<meta property="og:site_name" content="h3110w0r1d&#39;s Blog">
<meta property="og:description" content="hive数 据定义语言DDL数据定义语言概述   数据定义语言 (Data Definition Language, DDL)，是SQL语言集中对数据库内部的对象结构进行创建，删除，修改等的操作语言，这些数据库对象包括database（schema）、table、view、index等。   DDL核心语法由CREATE、ALTER与DROP三个所组成。DDL是对表结构进行的操作。   在某些上下">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/QQ图片20240111033823.jpg">
<meta property="article:published_time" content="2022-11-14T10:41:23.298Z">
<meta property="article:modified_time" content="2024-01-10T10:15:13.987Z">
<meta property="article:author" content="h3110w0r1d">
<meta property="article:tag" content="hive">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/QQ图片20240111033823.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://www.codexploit.cn/hive%E6%95%B0%E6%8D%AE%E5%AE%9A%E4%B9%89%E8%AF%AD%E8%A8%80DDL/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.12.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'hive数据定义语言DDL',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-01-10 18:15:13'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/QQ图片20240111033823.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">106</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">50</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">70</div></a></div><hr class="custom-hr"/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="h3110w0r1d's Blog"><span class="site-name">h3110w0r1d's Blog</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">hive数据定义语言DDL</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-11-14T10:41:23.298Z" title="发表于 2022-11-14 18:41:23">2022-11-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-10T10:15:13.987Z" title="更新于 2024-01-10 18:15:13">2024-01-10</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/hive/">hive</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="hive数据定义语言DDL"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="hive数-据定义语言DDL"><a href="#hive数-据定义语言DDL" class="headerlink" title="hive数 据定义语言DDL"></a>hive数 据定义语言DDL</h1><h2 id="数据定义语言概述"><a href="#数据定义语言概述" class="headerlink" title="数据定义语言概述"></a>数据定义语言概述</h2><ol>
<li>  数据定义语言 (Data Definition Language, DDL)，是SQL语言集中对数据库内部的对象结构进行创建，删除，修改等的操作语言，这些数据库对象包括database（schema）、table、view、index等。</li>
<li>  DDL核心语法由CREATE、ALTER与DROP三个所组成。DDL是对表结构进行的操作。</li>
<li>  在某些上下文中，该术语也称为数据描述语言，因为它描述了数据库表中的字段和记录。</li>
</ol>
<h2 id="Hive-DDL操作"><a href="#Hive-DDL操作" class="headerlink" title="Hive DDL操作"></a>Hive DDL操作</h2><h3 id="DDL基本概念"><a href="#DDL基本概念" class="headerlink" title="DDL基本概念"></a>DDL基本概念</h3><ol>
<li>  在Hive中，DATABASE的概念和RDBMS中类似，我们称之为数据库，DATABASE和SCHEMA是可互换的，都可以使用。</li>
<li>  hive的数据库本质上就是一个目录</li>
<li>  默认的数据库叫做default,存储于/user/hive/warehouse下</li>
<li>  用户自己创建的数据库存储位置是/user/hive/warehouse/数据库名.db下</li>
</ol>
<h3 id="数据库的基本命令"><a href="#数据库的基本命令" class="headerlink" title="数据库的基本命令"></a>数据库的基本命令</h3><ol>
<li><p>  show databases 查看系统中所有的数据库</p>
</li>
<li><p>```<br>  show databases;</p>
  <pre class="line-numbers language-none"><code class="language-none">
3.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221114193204.png)

4.   create table 创建数据库

5.   &#96;&#96;&#96;hive
     create (DATABASE|SCHEMA) [IF NOT EXISTS] database_name
     [COMMENT database_comment] -- COMMENT用来添加数据库的注释说明语句
     [LOCATION hdfs_path] -- LOCATION用来指定数据库在HDFS的存储位置，默认&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;dbname.db
     [WITH DBPROPERTIES (proterty_name &#x3D; property_value,...)];<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>  如果需要使用location指定路径的时候，最好指向的是一个新创建的空文件夹</p>
</li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221114194309.png"></p>
</li>
<li><p>  describe database 查看数据库结构</p>
</li>
<li><p>  显示hive中数据库的名称，注释（如果已经设置），及其在文件系统中的位置等信息</p>
</li>
<li><p>  extended关键字用于显示更多的信息，可以将describe简写成desc来使用</p>
</li>
<li><p>```hive<br>  describe database/schema extended db_name;<br>  desc database [extend] db_name;</p>
  <pre class="line-numbers language-none"><code class="language-none">
12.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221114200306.png)

13.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221114200312.png)

14.   use database;选择当前的数据库

15.   &#96;&#96;&#96;hive
      use database db_name;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>  alter database 修改数据库的内容</p>
</li>
<li><p>  更改与Hive中的数据库相关联的元数据</p>
</li>
<li><p>```hive<br>  alter (database|schema) database_name set dbproperties (property_name=property_value,…); – 更改数据库的属性</p>
  <pre class="line-numbers language-none"><code class="language-none">
19.   &#96;&#96;&#96;hive
      alter (database|schema) database_name set OWNER USER user; -- 更改数据库的所有者<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
<li><p>```hive<br>  alter (database|schema) database_name set location hdfs_path; – 更改数据库的位置</p>
  <pre class="line-numbers language-none"><code class="language-none">
21.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221114201434.png)

22.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221114201439.png)

23.   drop database 删除数据库

24.   默认行为是RESTRICT,意味着仅在数据库为空时才删除它

25.   要删除带有表的数据库（不为空的数据库），我们可以使用CASCADE

26.   &#96;&#96;&#96;hive
      DROP (DATABASE|SCHEMA) [IF EXISTS] database_name [RESTRICT|CASCADE];<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221114204811.png"></p>
</li>
</ol>
<h3 id="Hive表的基本命令"><a href="#Hive表的基本命令" class="headerlink" title="Hive表的基本命令"></a>Hive表的基本命令</h3><ol>
<li><p>  show tables;查看hive表的列表</p>
</li>
<li><p>```hive<br>  show tables in 数据库名;</p>
  <pre class="line-numbers language-none"><code class="language-none">
3.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221114205024.png)

4.   创建表的语法树

5.   &#96;&#96;&#96;hive
      CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name  
      [(col_name data_type [COMMENT col_comment], ... ]  
      [COMMENT table_comment]  
      [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]  
      [CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS]  
      [ROW FORMAT DELIMITED|SERDE serde_name WITH SERDEPROPERTIES (property_name&#x3D;property_value,...)]  
      [STORED AS file_format]  
      [LOCATION hdfs_path]  
      [TBLPROPERTIES (property_name&#x3D;property_value, ...)];
     -- 建表语法中的语法顺序需要和语法树中的一致<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>  建表语法中的语法顺序需要和语法树中的一致</p>
</li>
</ol>
<h2 id="Hive数据类型"><a href="#Hive数据类型" class="headerlink" title="Hive数据类型"></a>Hive数据类型</h2><ol>
<li><p>  数据类型指的是表中列的字段类型</p>
</li>
<li><p>  分为：原生数据类型和复杂数据类型</p>
</li>
<li><p>  原生数据类型包括：数值类型、时间日期类型、字符串类型、杂项数据类型；</p>
</li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221114210333.png"></p>
</li>
<li><p>  复杂数据类型包括：array数组、map映射、struct结构、union联合体。</p>
</li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221114210350.png"></p>
</li>
<li><p>  因为底层是用Java写的，所以支持Java的数据类型，比如字符串string</p>
</li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221114210535.png"></p>
</li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221114210636.png"></p>
</li>
<li><p>  显示类型转换使用CAST函数</p>
</li>
<li><p>```hive<br>  CAST(‘100’ as INT) – 会将字符串100转换为100整数值<br>  – 如果强制类型转换失败，函数会返回NULL</p>
  <pre class="line-numbers language-none"><code class="language-none">
12.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221114211004.png)

13.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221114211011.png)

### 默认分隔符

1.   Hive建表时如果没有row format语法指定分隔符，则采用默认分隔符，是用来分隔字段的，默认的分割符是‘\001&#39;，是一种特殊的字符，使用的是ASCII编码的值，键盘是打不出来的。
2.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221114211310.png)
3.   在vim编辑器中，连续按下Ctrl+v&#x2F;Ctrl+a即可输入&#39;\001&#39; ，显示^A
4.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221114211526.png)
5.   在一些文本编辑器中将以SOH的形式显示：
6.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221114211637.png)

## Hive数据存储路径

1.   将数据放在表目录下，即可映射数据到Hive表中

2.   &#96;&#96;&#96;hive
     hadoop fs -put stuent2.txt &#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;mydb1.db&#x2F;student2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>  在Hive建表的时候，可以<strong>通过location语法</strong>来<strong>更改数据在HDFS上的存储路径</strong>，使得建表加载数据更加灵活方便。</p>
</li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221114212524.png"></p>
</li>
</ol>
<h2 id="查看Hive表的结构"><a href="#查看Hive表的结构" class="headerlink" title="查看Hive表的结构"></a>查看Hive表的结构</h2><ol>
<li><p>  describe 表名</p>
</li>
<li><p>  显示Hive中表的元数据信息，如果指定了EXTENDED关键字，则它将以Thrift序列化形式显示表的所有元数据；如果指定了FORMATTED关键字，则它将以表格格式显示元数据。</p>
</li>
<li><p>  取表中指定的数据创建一个新表，使用AS指定SQL查询语句，查询语句的结果即为新表的结构和内容</p>
</li>
<li><p>```hive<br>  create table if not exists student5 as select id,name from student1 where age &gt;= 20;</p>
  <pre class="line-numbers language-none"><code class="language-none">
## LIKE创建表

1.   使用LIKE创建一张表结构与某个表相同的新表，新表中内容为空。

2.   &#96;&#96;&#96;hive
     create table if not exists student6 like student1;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>  类似于拷贝一张表的结构</p>
</li>
</ol>
<h2 id="元数据和主数据的区别"><a href="#元数据和主数据的区别" class="headerlink" title="元数据和主数据的区别"></a>元数据和主数据的区别</h2><ol>
<li>  <strong>元数据</strong>：即<strong>关于数据的数据</strong>，用以描述数据及其环境的结构化信息，便于查找、理解、使用和管理数据。</li>
<li>  <strong>主数据</strong>：主数据则定义企业核心业务对象，如客户、产品、地址等，与交易流水信息不同，主数据一旦被记录到数据库中，需要经常对其进行维护，从而确保其时效性和准确性；主数据还包括关系数据，用以描述主数据之间的关系，如客户与产品的关系、产品与地域的关系、客户与客户的关系、产品与产品的关系等。</li>
</ol>
<h2 id="Hive的内部表和外部表"><a href="#Hive的内部表和外部表" class="headerlink" title="Hive的内部表和外部表"></a>Hive的内部表和外部表</h2><ol>
<li><p>  <strong>内部表也被称为被Hive拥有和管理的托管表</strong></p>
</li>
<li><p>  默认情况下创建的表就是内部表，Hive拥有该表的结构和文件。换句话说，Hive完全管理表（元数据和数据）的生命周期，类似于RDBMS中的表。</p>
</li>
<li><p>  当删除内部表时，会删除数据以及表的元数据（元数据指的是数据的属性信息，而不是具体的数据）</p>
</li>
<li><p>  可以使用DESCRIBE FORMATTED table_name 来获取表的元数据信息，从中可以看出表的类型</p>
</li>
<li><p>```hive<br>  DESCRIBE FORMATTED table_name;</p>
  <pre class="line-numbers language-none"><code class="language-none">
6.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221114220742.png)

7.   外部表：外部表中的数据不是Hive拥有或管理的，只管理表元数据的生命周期

8.   要创建一个外部表，需要使用EXTERNAL关键字

9.   删除外部表只会删除元数据，而不会删除实际数据，在Hive外部仍然可以访问实际数据

### 内外部表的相同和不同之处

1.   都会在Hive **Metastore中管理**表的定义、字段类型等**元数据信息**
2.   删除**内部表**时，除了会从Metastore中删除表元数据，还**会从HDFS中删除其所有数据文件**。
3.   删除**外部表**时，只会从Metastore中删除表的元数据，并**保持HDFS位置中的实际数据不变**。

## DDL表的修改和删除

1.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221114222014.png)

2.   drop语句可以指定垃圾桶

3.   &#96;&#96;&#96;hive
     drop table [if exists] table_name [PURGE];<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221114222116.png"></p>
</li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221114222252.png"></p>
</li>
</ol>
<h2 id="普通表数据加载"><a href="#普通表数据加载" class="headerlink" title="普通表数据加载"></a>普通表数据加载</h2><h3 id="加载本地数据"><a href="#加载本地数据" class="headerlink" title="加载本地数据"></a>加载本地数据</h3><ol>
<li><p>  创建一张普通表</p>
</li>
<li><p>```hive<br>  create table t_student(<br>  num int,<br>  name string,<br>  sex string,<br>  age int,<br>  dept string)<br>  row format delimited fields terminated by ‘,’;<br>  – delimited fields的意思是分隔字段，delimited指分隔的<br>  – fields 字段<br>  – terminated by 终止于<br>  – 行格式分隔符，采用行格式进行分隔</p>
  <pre class="line-numbers language-none"><code class="language-none">
3.   将本地数据加载进这张普通表中

4.   &#96;&#96;&#96;hive
     load data local inpath 本地文件及路径 [overwrite] into table 表明;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221114191539.png"></p>
</li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221114191546.png"></p>
</li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221114191558.png"></p>
</li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221114191604.png"></p>
</li>
</ol>
<h3 id="加载HDFS中的数据"><a href="#加载HDFS中的数据" class="headerlink" title="加载HDFS中的数据"></a>加载HDFS中的数据</h3><ol>
<li><p>```hive<br>  load data inpath ‘/hivedata/student.txt’ overwrite into table t_student;<br>  – 没有local参数即为从HDFS中取数据并加载</p>
  <pre class="line-numbers language-none"><code class="language-none">
2.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221114191829.png)

3.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221114191833.png)

### 插入数据 insert + select (需要执行MR程序)

1.   &#96;&#96;&#96;hive
     insert into table table_name select xxx from othertablename;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221114192009.png"></p>
</li>
</ol>
<h2 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h2><h3 id="分区表的产生原因"><a href="#分区表的产生原因" class="headerlink" title="分区表的产生原因"></a>分区表的产生原因</h3><ol>
<li>  where语句的背后需要进行全表扫描才能过滤出结果，对于hive来说需要扫描每一个文件。如果数据文件个数特别多的话，扫描效率很慢也没必要。</li>
<li>  如果只需求需要一个archer.txt文件，只需要扫描archer.txt文件即可，如何优化可以加快查询，减少全表扫描呢？</li>
<li>  指定文件扫描和全表扫描，效率还是存在差异的。</li>
<li>  分区表的创建目的就是为了减少扫描文件的大小，减少全表扫描的概率，提高效率</li>
<li>  当Hive表对应的数据量大、文件个数多时，<strong>为了避免查询时全表扫描数据</strong>，Hive<strong>支持根据指定的字段对表进行分区</strong>，分区的字段可以是日期、地域、种类等具有标识意义的字段。</li>
<li>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221115163907.png"></li>
</ol>
<h2 id="分区表的创建和数据加载"><a href="#分区表的创建和数据加载" class="headerlink" title="分区表的创建和数据加载"></a>分区表的创建和数据加载</h2><ol>
<li><p>  <strong>分区字段不能与表中已经存在的字段同名</strong>，分区字段可以<strong>以虚拟字段的形式</strong>显示在表结构的最后</p>
</li>
<li><p>```hive<br>  –分区表建表语法<br>  CREATE TABLE table_name (<br>  column1 data_type, <br>  column2 data_type,<br>  ….) <br>  PARTITIONED BY (partition1 data_type, partition2 data_type,…);</p>
  <pre class="line-numbers language-none"><code class="language-none">
3.   &#96;&#96;&#96;hive
     create table t_all_hero_part(
     id int,
     name string,
     hp_max int,
     mp_max int,
     attack_max int,
     defense_max int,
     attack_range string,
     role_assist string
     ) partitioned by (role_main string) -- 这里是分区字段
     row format delimited
     fields terminated by &quot;\t&quot;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221115164953.png"></p>
</li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221115165209.png"></p>
</li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221115165921.png"></p>
</li>
<li><p>```hive<br>  load data local inpath ‘/root/hivedata/archer.txt’ into table t_all_hero_part partition(role_main=’sheshou’);<br>  load data local inpath ‘/root/hivedata/assassin.txt’ into table t_all_hero_part partition(role _main =’cike’);load data local inpath ‘/root/hivedata/mage.txt’ into table t_all_hero_part partition(role _main =’fashi’);</p>
  <pre class="line-numbers language-none"><code class="language-none">
8.   我的理解是：实际字段可以不包含**源数据**中的所有列，但是**实际字段+虚拟字段（partition字段）要能对应源数据中的每一个列**

9.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221115173138.png)

10.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221115173304.png)

11.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221115173248.png)

### 分区表和普通表的区别

1.   外表上看起来分区表好像没多大变化，实际上**分区表在底层管理数据的方式发生了改变**。
2.   普通表
3.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221115190253.png)
4.   分区表
5.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221115190301.png)
6.   分区的概念提供了一种**将Hive表数据分离为多个文件&#x2F;目录的方法**。
7.   **不同分区对应着不同的文件夹**，同一分区的数据存储在同一个文件夹下
8.   这种指定分区查询的方式叫做**分区裁剪**。

### 分区表的重点在于

1.   建表时根据业务场景**设置合适的分区字段**。比如日期、地域、类别等

2.   查询的时候尽量**先使用where进行分区过滤**，查询**指定分区的数据**，**避免全表扫描**

3.   &#96;&#96;&#96;hive
     select count(*) from t_all_hero where role_main&#x3D;&#39;archer&#39; and hp_max &gt; 5800;
     select count(*) from t_all_hero where role_main&#x3D;&#39;sheshou&#39; and hp_max &gt; 5800;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>  分区字段不能和表中已有的字段同名</p>
</li>
<li><p>  分区字段是虚拟字段，其数据并不存储在底层的文件中</p>
</li>
<li><p>  分区字段值的确定来自于<strong>用户价值数据手动指定</strong>（静态分区）或者根据<strong>查询结果位置自动推断</strong>（动态分区）</p>
</li>
<li><p>  Hive<strong>支持多重分区</strong>，也就是说在分区的基础上继续分区，划分更加细粒度</p>
</li>
</ol>
<h3 id="分区表的数据加载"><a href="#分区表的数据加载" class="headerlink" title="分区表的数据加载"></a>分区表的数据加载</h3><h4 id="动态分区插入"><a href="#动态分区插入" class="headerlink" title="动态分区插入"></a>动态分区插入</h4><ol>
<li><p>  所谓<strong>动态分区指的是分区的字段值是基于查询结果（参数位置）自动推断出来的</strong>。</p>
</li>
<li><p>  核心语法就是insert+select</p>
</li>
<li><p>```hive<br>  insert into table table_name PARTITION(分区字段) SELECT *** FROM othertable_name;</p>
  <pre class="line-numbers language-none"><code class="language-none">
4.   启动动态分区需要开启动态分区功能，在hive会话中设置几个参数

5.   &#96;&#96;&#96;hive
     set hive.exec.dynamic.partition&#x3D;true; -- 是否开启动态分区功能
     set hive.exec.dynamic.partition.mode&#x3D;nonstrict; -- 指定动态分区模式，分为nonstrick非严格模式和strict严格模式 , strict严格模式要求至少有一个分区为静态分区
     set hive.exec.max.dynamic.partitions&#x3D;50000;
     set hive.exec.max.dynamic.partitions.pernode&#x3D;10000;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>```hive<br>  – 创建一张表<br>  create table t_usa_covid19(<br>  count_date string,<br>  county string,<br>  state string,<br>  fips int,<br>  cases int,<br>  deaths int)<br>  row format delimited<br>  fields terminated by ‘,’;</p>
  <pre class="line-numbers language-none"><code class="language-none">
7.   &#96;&#96;&#96;bash
     -- 将所有的数据都加载进去
     hadoop fs -put us-covid19-countries.dat &#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;mydb2.db&#x2F;t_usa_covid19;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221115193714.png"></p>
</li>
<li><p>  <img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/20221115193953.png"></p>
</li>
<li><p>  多重分区表</p>
</li>
<li><p>```hive<br>  partitioned by (partition1 data_type,partition2,data_type,…)</p>
  <pre class="line-numbers language-none"><code class="language-none">
12.   多重分区下，分区之间是一种递进关系，可以理解为**在前一个分区的基础上继续分区**。从HDFS的角度来看就是**文件夹下继续划分子文件夹**。

13.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221115194448.png)

14.   &#96;&#96;&#96;hive
      --单分区表，按省份分区
      create table t_user_province (id int, name string,age int) partitioned by (province string);
      --双分区表，按省份和市分区
      create table t_user_province_city (id int, name string,age int) partitioned by (province string, city string);
      --三分区表，按省份、市、县分区
      create table t_user_province_city_county (id int, name string,age int) partitioned by (province string, city string,county string);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ol>
<h3 id="对于分区表的DDL操作"><a href="#对于分区表的DDL操作" class="headerlink" title="对于分区表的DDL操作"></a>对于分区表的DDL操作</h3><ol>
<li><p>  主要包括：增加分区，删除分区，修改分区</p>
</li>
<li><p>  增加分区：</p>
</li>
<li><p>```hive<br>  alter table 表名 add partition (分区字段)<br>  location ‘分区字段需要的数据文件所在的HDFS位置’</p>
  <pre class="line-numbers language-none"><code class="language-none">
## 分桶表

1.   分桶表对应的数据文件**在底层会被分解为若干个部分**，通俗来说就是**被拆分成若干个独立的小文件**。

2.   在分桶时，要指定根据哪个字段将数据分为几桶（几个部分）。

3.   ![](https:&#x2F;&#x2F;strongwillpro.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20221115203849.png)

4.   &#96;&#96;&#96;hive
     create [external] table [db_name.]table_name
     [(col_name data_type,...)]
     clustered by(col_name) -- clustered by 根据哪个字段进行分
     into N buckets; -- 分成几桶<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://www.codexploit.cn">h3110w0r1d</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://www.codexploit.cn/hive%E6%95%B0%E6%8D%AE%E5%AE%9A%E4%B9%89%E8%AF%AD%E8%A8%80DDL/">https://www.codexploit.cn/hive%E6%95%B0%E6%8D%AE%E5%AE%9A%E4%B9%89%E8%AF%AD%E8%A8%80DDL/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.codexploit.cn" target="_blank">h3110w0r1d's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/hive/">hive</a></div><div class="post_share"><div class="social-share" data-image="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/QQ图片20240111033823.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/docker-k8s%E4%BA%91%E5%8E%9F%E7%94%9F/" title="K8s+Docker+KubeSphere+DevOps"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">K8s+Docker+KubeSphere+DevOps</div></div></a></div><div class="next-post pull-right"><a href="/virtualbox%E5%AF%BC%E5%85%A5hadoop%E9%9B%86%E7%BE%A4/" title="virtual导入hadoop集群"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">virtual导入hadoop集群</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://strongwillpro.oss-cn-beijing.aliyuncs.com/img/QQ图片20240111033823.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">h3110w0r1d</div><div class="author-info__description">CTF web手、Golang后端开发工程师 研究多线程高并发、渗透测试      Web安全</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">106</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">50</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">70</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/dezhoutorizhao?tab=repositories"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">h3110w0r1d师傅又发布了新博客了，快去看看吧</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#hive%E6%95%B0-%E6%8D%AE%E5%AE%9A%E4%B9%89%E8%AF%AD%E8%A8%80DDL"><span class="toc-number">1.</span> <span class="toc-text">hive数 据定义语言DDL</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%AE%9A%E4%B9%89%E8%AF%AD%E8%A8%80%E6%A6%82%E8%BF%B0"><span class="toc-number">1.1.</span> <span class="toc-text">数据定义语言概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-DDL%E6%93%8D%E4%BD%9C"><span class="toc-number">1.2.</span> <span class="toc-text">Hive DDL操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#DDL%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">1.2.1.</span> <span class="toc-text">DDL基本概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4"><span class="toc-number">1.2.2.</span> <span class="toc-text">数据库的基本命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4"><span class="toc-number">1.2.3.</span> <span class="toc-text">Hive表的基本命令</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.3.</span> <span class="toc-text">Hive数据类型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8BHive%E8%A1%A8%E7%9A%84%E7%BB%93%E6%9E%84"><span class="toc-number">1.4.</span> <span class="toc-text">查看Hive表的结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%83%E6%95%B0%E6%8D%AE%E5%92%8C%E4%B8%BB%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">1.5.</span> <span class="toc-text">元数据和主数据的区别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive%E7%9A%84%E5%86%85%E9%83%A8%E8%A1%A8%E5%92%8C%E5%A4%96%E9%83%A8%E8%A1%A8"><span class="toc-number">1.6.</span> <span class="toc-text">Hive的内部表和外部表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%99%AE%E9%80%9A%E8%A1%A8%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD"><span class="toc-number">1.7.</span> <span class="toc-text">普通表数据加载</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E6%9C%AC%E5%9C%B0%E6%95%B0%E6%8D%AE"><span class="toc-number">1.7.1.</span> <span class="toc-text">加载本地数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BDHDFS%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE"><span class="toc-number">1.7.2.</span> <span class="toc-text">加载HDFS中的数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E8%A1%A8"><span class="toc-number">1.8.</span> <span class="toc-text">分区表</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E8%A1%A8%E7%9A%84%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0"><span class="toc-number">1.8.1.</span> <span class="toc-text">分区表的产生原因</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E8%A1%A8%E7%9A%84%E5%88%9B%E5%BB%BA%E5%92%8C%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD"><span class="toc-number">1.9.</span> <span class="toc-text">分区表的创建和数据加载</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E8%A1%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD"><span class="toc-number">1.9.1.</span> <span class="toc-text">分区表的数据加载</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E5%88%86%E5%8C%BA%E6%8F%92%E5%85%A5"><span class="toc-number">1.9.1.1.</span> <span class="toc-text">动态分区插入</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E4%BA%8E%E5%88%86%E5%8C%BA%E8%A1%A8%E7%9A%84DDL%E6%93%8D%E4%BD%9C"><span class="toc-number">1.9.2.</span> <span class="toc-text">对于分区表的DDL操作</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023%E5%A4%8D%E7%9B%98/" title="2023复盘">2023复盘</a><time datetime="2024-01-10T16:41:46.332Z" title="发表于 2024-01-11 00:41:46">2024-01-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/%E4%BE%A7%E4%BF%A1%E9%81%93%E6%94%BB%E5%87%BB/" title="侧信道攻击">侧信道攻击</a><time datetime="2023-09-26T09:03:09.760Z" title="发表于 2023-09-26 17:03:09">2023-09-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/%E8%93%9D%E5%B8%BD%E6%9D%AF%E5%8D%8A%E5%86%B3%E8%B5%9B_%E7%94%B5%E5%AD%90%E5%8F%96%E8%AF%81/" title="蓝帽杯半决赛wp_电子取证部分">蓝帽杯半决赛wp_电子取证部分</a><time datetime="2023-09-16T13:26:55.732Z" title="发表于 2023-09-16 21:26:55">2023-09-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/%E8%93%9D%E5%B8%BD%E6%9D%AF%E5%8D%8A%E5%86%B3%E8%B5%9B_web/" title="蓝帽杯半决赛wp_web部分">蓝帽杯半决赛wp_web部分</a><time datetime="2023-09-16T13:18:03.466Z" title="发表于 2023-09-16 21:18:03">2023-09-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" title="数据结构">数据结构</a><time datetime="2023-08-30T08:37:08.678Z" title="发表于 2023-08-30 16:37:08">2023-08-30</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By h3110w0r1d</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.12.0"></script><script src="/js/main.js?v=4.12.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>